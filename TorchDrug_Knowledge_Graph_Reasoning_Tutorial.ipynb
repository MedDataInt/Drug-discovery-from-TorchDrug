{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedDataInt/Drug-discovery-from-TorchDrug/blob/main/TorchDrug_Knowledge_Graph_Reasoning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQPnwWiVdZ1p"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In knowledge graphs, one important task is knowledge graph reasoning, which aims at predicting missing (h,r,t)-links given existing (h,r,t)-links in a knowledge graph. There are two kinds of well-known approaches to knowledge graph reasoning. One is knowledge graph embedding and the other one is neural inductive logic programming.\n",
        "\n",
        "In this tutorial, we provide two examples to illustrate how to use TorchDrug for knowledge graph reasoning.\n",
        "\n",
        "### Manual Steps\n",
        "\n",
        "1.   Get your own copy of this file via \"File > Save a copy in Drive...\",\n",
        "2.   Set the runtime to **GPU** via \"Runtime > Change runtime type...\"\n",
        "\n",
        "### Colab Tutorials\n",
        "\n",
        "#### Quick Start\n",
        "1. [Basic Usage and Pipeline](https://colab.research.google.com/drive/1Tbnr1Fog_YjkqU1MOhcVLuxqZ4DC-c8-#forceEdit=true&sandboxMode=true)\n",
        "\n",
        "#### Drug Discovery Tasks\n",
        "1. [Property Prediction](https://colab.research.google.com/drive/1sb2w3evdEWm-GYo28RksvzJ74p63xHMn?usp=sharing#forceEdit=true&sandboxMode=true)\n",
        "2. [Pretrained Molecular Representations](https://colab.research.google.com/drive/10faCIVIfln20f2h1oQk2UrXiAMqZKLoW?usp=sharing#forceEdit=true&sandboxMode=true)\n",
        "3. [De Novo Molecule Design](https://colab.research.google.com/drive/1JEMiMvSBuqCuzzREYpviNZZRVOYsgivA?usp=sharing#forceEdit=true&sandboxMode=true)\n",
        "4. [Retrosynthesis](https://colab.research.google.com/drive/1IH1hk7K3MaxAEe5m6CFY7Eyej3RuiEL1?usp=sharing#forceEdit=true&sandboxMode=true)\n",
        "5. [Knowledge Graph Reasoning](https://colab.research.google.com/drive/1-sjqQZhYrGM0HiMuaqXOiqhDNlJi7g_I?usp=sharing#forceEdit=true&sandboxMode=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpM2xMHNyPlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786cabca-84c5-445f-eb2b-94d62c1bd5e7"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ[\"TORCH_VERSION\"] = torch.__version__\n",
        "\n",
        "!pip install torch-scatter torch-cluster -f https://pytorch-geometric.com/whl/torch-$TORCH_VERSION.html\n",
        "!pip install torchdrug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.8\n",
            "Collecting torchdrug\n",
            "  Downloading torchdrug-0.1.1.post1-py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdrug) (1.9.0+cu111)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torchdrug) (2.6.3)\n",
            "Requirement already satisfied: torch-scatter>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdrug) (2.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchdrug) (4.62.3)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from torchdrug) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torchdrug) (2.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torchdrug) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from torchdrug) (1.19.5)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.3.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->torchdrug) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torchdrug) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdrug) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdrug) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdrug) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torchdrug) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->torchdrug) (1.15.0)\n",
            "Installing collected packages: rdkit-pypi, ninja, torchdrug\n",
            "Successfully installed ninja-1.10.2.2 rdkit-pypi-2021.3.5.1 torchdrug-0.1.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFmpTG8ccZQJ"
      },
      "source": [
        "# Knowledge Graph Embedding\n",
        "\n",
        "For knowledge graph reasoning, the first kind of popular method is the knowledge graph embedding method. The basic idea is to learn an embedding vector for each entity and relation in a knowledge graph based on existing (h,r,t)-links. Then these embeddings are further used to predict missing links.\n",
        "\n",
        "Next, we will introduce how to use knowledge graph embedding models for knowledge graph reasoning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSJY3U_MnOw"
      },
      "source": [
        "## Prepare the Dataset\n",
        "\n",
        "We use the FB15k-237 dataset for illustration. FB15k-237 is constructed from Freebase, and the dataset has 14,541 entities as well as 237 relations. For the dataset, there is a standard split of training/validation/test sets. We can load the dataset using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb8oU4BZUCmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90fefdb-44d7-492b-aff6-83978c6b6a84"
      },
      "source": [
        "import torch\n",
        "from torchdrug import core, datasets, tasks, models\n",
        "\n",
        "dataset = datasets.FB15k237(\"~/kg-datasets/\")\n",
        "train_set, valid_set, test_set = dataset.split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /root/kg-datasets/fb15k237_train.txt: 100%|██████████| 272115/272115 [00:00<00:00, 389030.77it/s]\n",
            "Loading /root/kg-datasets/fb15k237_valid.txt: 100%|██████████| 17535/17535 [00:00<00:00, 314543.20it/s]\n",
            "Loading /root/kg-datasets/fb15k237_test.txt: 100%|██████████| 20466/20466 [00:00<00:00, 382310.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X0nSAoGUNBl"
      },
      "source": [
        "## Define our Model\n",
        "\n",
        "Once we load the dataset, we are ready to build the model. Let’s take the RotatE model as an example, we can use the following code for model construction.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYuCkxBGUPgQ"
      },
      "source": [
        "model = models.RotatE(num_entity=dataset.num_entity,\n",
        "                      num_relation=dataset.num_relation,\n",
        "                      embedding_dim=2048, max_score=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnldvrV8ddDk"
      },
      "source": [
        "Here, embedding_dim specifies the dimension of entity and relation embeddings. max_score specifies the bias for inferring the plausibility of a (h,r,t) triplet.\n",
        "\n",
        "You may consider using a smaller embedding dimension for better efficiency.\n",
        "\n",
        "Afterwards, we further need to define our task. For the knowledge graph embedding task, we can simply use the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txc1o868derw"
      },
      "source": [
        "task = tasks.KnowledgeGraphCompletion(model, num_negative=256,\n",
        "                                      adversarial_temperature=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etF_eznadgaE"
      },
      "source": [
        "Here, num_negative is the number of negative examples used for training, and adversarial_temperature is the temperature for sampling negative examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCLNWIHUM9EX"
      },
      "source": [
        "## Train and Test\n",
        "\n",
        "Afterwards, we can now train and test our model. For model training, we need to set up an optimizer and put everything together into an Engine instance with the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7TR1YBjdiwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fd6e20-f52a-4e35-b5f0-922d3ccdaab4"
      },
      "source": [
        "optimizer = torch.optim.Adam(task.parameters(), lr=2e-5)\n",
        "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
        "                     gpus=[0], batch_size=1024)\n",
        "solver.train(num_epoch=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:37:42   Preprocess training set\n",
            "09:38:05   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:38:05   Epoch 0 begin\n",
            "09:39:21   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:39:21   binary cross entropy: 0.706805\n",
            "09:39:35   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:39:35   binary cross entropy: 0.705627\n",
            "09:39:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:39:49   binary cross entropy: 0.694933\n",
            "09:39:58   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:39:58   Epoch 0 end\n",
            "09:39:58   duration: 2.28 mins\n",
            "09:39:58   speed: 1.95 batch / sec\n",
            "09:39:58   ETA: 2.28 mins\n",
            "09:39:58   max GPU memory: 1146.0 MiB\n",
            "09:39:58   ------------------------------\n",
            "09:39:58   average binary cross entropy: 0.700414\n",
            "09:39:58   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:39:58   Epoch 1 begin\n",
            "09:40:03   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:40:03   binary cross entropy: 0.638479\n",
            "09:40:17   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:40:17   binary cross entropy: 0.636243\n",
            "09:40:31   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:40:31   binary cross entropy: 0.639614\n",
            "09:40:36   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:40:36   Epoch 1 end\n",
            "09:40:36   duration: 37.28 secs\n",
            "09:40:36   speed: 7.14 batch / sec\n",
            "09:40:36   ETA: 0.00 secs\n",
            "09:40:36   max GPU memory: 1145.9 MiB\n",
            "09:40:36   ------------------------------\n",
            "09:40:36   average binary cross entropy: 0.638924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs0ksqU6NAaH"
      },
      "source": [
        "Here, we can reduce num_epoch for better efficiency.\n",
        "\n",
        "Afterwards, we may further evaluate the model on the validation set using the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VpYnDPUOwww",
        "outputId": "4be28195-3ea9-4d64-ce2f-7862af0c3703"
      },
      "source": [
        "solver.evaluate(\"valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:40:36   Evaluate on valid\n",
            "09:41:27   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:41:27   hits@1: 0.00861135\n",
            "09:41:27   hits@10: 0.0401198\n",
            "09:41:27   hits@3: 0.0163102\n",
            "09:41:27   mr: 3867.03\n",
            "09:41:27   mrr: 0.0195721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hits@1': tensor(0.0086),\n",
              " 'hits@10': tensor(0.0401),\n",
              " 'hits@3': tensor(0.0163),\n",
              " 'mr': tensor(3867.0286),\n",
              " 'mrr': tensor(0.0196)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htz21au8cubx"
      },
      "source": [
        "# Neural Inductive Logic Programming\n",
        "\n",
        "The other kind of popular method is neural inductive logic programming. The idea of neural inductive logic programming is to learn logic rules from training data. Once the logic rules are learned, they can be further used to predict missing links.\n",
        "\n",
        "One popular method of neural inductive logic programming is NeuralLP. NeuralLP considers all the chain-like rules (e.g., nationality = born_in + city_of) up to a maximum length. Also, an attention mechanism is used to assign a scalar weight to each logic rule. During training, the attention module is trained, so that we can learn a proper weight for each rule. During testing, the logic rules and their weights are used together to predict missing links.\n",
        "\n",
        "Next, we will introduce how to deploy a NeuralLP model for knowledge graph reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-hSPLkeNHPd"
      },
      "source": [
        "## Prepare the Dataset\n",
        "\n",
        "We start with loading the dataset. Similar to the tutorial of knowledge graph embedding, the FB15k-237 dataset is used for illustration. We can load the dataset by running the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq14KIdFUFtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8370be-7994-40d2-a004-b1a553618df8"
      },
      "source": [
        "import torch\n",
        "from torchdrug import core, datasets, tasks, models\n",
        "\n",
        "dataset = datasets.FB15k237(\"~/kg-datasets/\")\n",
        "train_set, valid_set, test_set = dataset.split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /root/kg-datasets/fb15k237_train.txt: 100%|██████████| 272115/272115 [00:00<00:00, 367622.05it/s]\n",
            "Loading /root/kg-datasets/fb15k237_valid.txt: 100%|██████████| 17535/17535 [00:00<00:00, 371337.58it/s]\n",
            "Loading /root/kg-datasets/fb15k237_test.txt: 100%|██████████| 20466/20466 [00:00<00:00, 366685.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fk4ANSdNMkS"
      },
      "source": [
        "## Define our Model\n",
        "\n",
        "Afterwards, we can now define the NeuralLP model with the following codes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNHIF9GFdoaH"
      },
      "source": [
        "model = models.NeuralLP(num_relation=dataset.num_relation,\n",
        "                        hidden_dim=128,\n",
        "                        num_step=3,\n",
        "                        num_lstm_layer=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWtALUwtdp-q"
      },
      "source": [
        "Here, embedding_dim is the dimension of entity and relation embeddings used in NeuralLP. num_step is the maximum length of the chain-like rules (i.e., the maximum number of relations in the body of a chain-like rule), which is typically set to 3. num_lstm_layer is the number of LSTM layers used in NeuralLP.\n",
        "\n",
        "Once we define our model, we are ready to define the task. As training NeuralLP shares similar ideas to training knowledge graph embedding, we also use the following knowledge graph embedding task:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2EgiI8WdsQC"
      },
      "source": [
        "task = tasks.KnowledgeGraphCompletion(model, fact_ratio=0.75,\n",
        "                                      num_negative=256,\n",
        "                                      sample_weight=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEmq03VZduOG"
      },
      "source": [
        "The difference is that we need to specify the fact_ratio, which tells the code how many facts are used to construct the background knowledge graph on which we perform reasoning, and this hyperparameter is typically set to 0.75.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNWsIvCpNaL9"
      },
      "source": [
        "## Train and Test\n",
        "\n",
        "With the model and task we have defined, we can not perform model training and testing. Model training is similar to that of knowledge graph embedding models, where we need to create an optimizer and feed every component into an Engine instance by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCXKQw0Bdvfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036cb318-9cd0-43f7-cacc-60c61c8d2d87"
      },
      "source": [
        "optimizer = torch.optim.Adam(task.parameters(), lr=1.0e-3)\n",
        "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
        "                     gpus=[0], batch_size=64)\n",
        "solver.train(num_epoch=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:41:29   Preprocess training set\n",
            "09:41:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:41:29   Epoch 0 begin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:41:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:41:29   binary cross entropy: 0.756594\n",
            "09:41:53   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:41:53   binary cross entropy: 0.693444\n",
            "09:42:17   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:42:17   binary cross entropy: 0.693135\n",
            "09:42:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:42:41   binary cross entropy: 0.693134\n",
            "09:43:05   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:43:06   binary cross entropy: 0.693136\n",
            "09:43:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:43:30   binary cross entropy: 0.693145\n",
            "09:43:53   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:43:54   binary cross entropy: 0.693142\n",
            "09:44:18   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:44:18   binary cross entropy: 0.693131\n",
            "09:44:42   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:44:42   binary cross entropy: 0.693128\n",
            "09:45:06   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:45:06   binary cross entropy: 0.693121\n",
            "09:45:30   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:45:30   binary cross entropy: 0.693123\n",
            "09:45:45   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:45:45   Epoch 0 end\n",
            "09:45:45   duration: 4.27 mins\n",
            "09:45:45   speed: 4.15 batch / sec\n",
            "09:45:45   ETA: 0.00 secs\n",
            "09:45:45   max GPU memory: 1003.7 MiB\n",
            "09:45:45   ------------------------------\n",
            "09:45:45   average binary cross entropy: 0.694755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82dMAcSLNgIQ"
      },
      "source": [
        "Here, gpus specifies the GPUs on which we would like to train the model. We may specify multiple GPUs by using the form as above. For num_epoch, we can reduce the value for efficiency purpose.\n",
        "\n",
        "After model training, we can further use the following codes to evaluate the model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-skX5zONghX",
        "outputId": "3f946fef-30e6-4d44-8729-3cb5fb76581b"
      },
      "source": [
        "solver.evaluate(\"valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:45:45   Evaluate on valid\n",
            "09:48:36   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "09:48:36   hits@1: 0\n",
            "09:48:36   hits@10: 0\n",
            "09:48:36   hits@3: 0\n",
            "09:48:36   mr: 12747\n",
            "09:48:36   mrr: 8.09675e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hits@1': tensor(0.),\n",
              " 'hits@10': tensor(0.),\n",
              " 'hits@3': tensor(0.),\n",
              " 'mr': tensor(12747.0469),\n",
              " 'mrr': tensor(8.0967e-05)}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}